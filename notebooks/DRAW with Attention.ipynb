{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0e0e76611cbb44ad62e64b6c33ebd88195c42ce7f4e3674c65dd3e7e45acb1af1",
   "display_name": "Python 3.8.10 64-bit (windows store)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e0e76611cbb44ad62e64b6c33ebd88195c42ce7f4e3674c65dd3e7e45acb1af1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# own imports\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from models import DRAW\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Load MNIST Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lambda func\n",
    "def tmp_lambda(x):\n",
    "    return torch.bernoulli(x)\n",
    "\n",
    "# Load the data\n",
    "mnist_data = MNIST(\n",
    "    './', \n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(tmp_lambda)\n",
    "    ])\n",
    ")\n",
    "\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': False} if cuda else {}\n",
    "data_loader = DataLoader(\n",
    "    mnist_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    # **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 216x432 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"196.918125pt\" version=\"1.1\" viewBox=\"0 0 181.8 196.918125\" width=\"181.8pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-27T16:33:31.284457</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 196.918125 \r\nL 181.8 196.918125 \r\nL 181.8 -0 \r\nL 0 -0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#pe7074252af)\">\r\n    <image height=\"168\" id=\"image3177f230fb\" transform=\"scale(1 -1)translate(0 -168)\" width=\"168\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAYAAAB0S6W0AAACkUlEQVR4nO3dUWrDMBBAQbv0/ldOT5CCWjl+kme+SxLKY2Fj2TmP43gdEPV19weA3wiUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGkCJU2gpAmUNIGSJlDSBEqaQEkTKGnfd3+Ap3u95jyW4DzPKa9TY4KSJlDSBEqaQEkTKGnn4el2HzFrW79a7dsAE5Q0gZImUNIESppASXMt/o+u3srfbdPv3nf071dhgpImUNIESppASRMoadtu8Xdtr7O279HX35UJSppASRMoaQIlTaCkbbvFX23X7XvWtw2zmKCkCZQ0gZImUNIEStryW7ynw+3NBCVNoKQJlDSBkiZQ0pbf4t/ZdStf/T73USYoaQIlTaCkCZQ0gZK2zBY/ur3WTobXrPJ/MEFJEyhpAiVNoKQJlLRltvhZW+fotwG7Pvt9FSYoaQIlTaCkCZQ0gZK27e/FP23LXuXa+igTlDSBkiZQ0gRKmkBJEyhpAiVNoKQJlDSBkiZQ0pY5UT9q9Nr0rPvoR1/naWcGRpmgpAmUNIGSJlDSBEratlv8qFkn0nc92X4XE5Q0gZImUNIESppASRMoaQIlTaCkCZQ0gZImUNJci5/MCfm5TFDSBEqaQEkTKGkCJW3aFn/1L7jNuq989fvTn3Zi3wQlTaCkCZQ0gZImUNIu/6W5p23Zo562lY8yQUkTKGkCJU2gpAmUtMtP1Ne21FlnAPgME5Q0gZImUNIESppASbv8Wjz8hwlKmkBJEyhpAiVNoKQJlDSBkiZQ0gRKmkBJEyhpAiVNoKQJlDSBkiZQ0gRKmkBJEyhpAiVNoKQJlDSBkiZQ0gRKmkBJEyhpAiVNoKQJlDSBkiZQ0gRKmkBJEyhpP02oVHCtrcLgAAAAAElFTkSuQmCC\" y=\"-21.718125\"/>\r\n   </g>\r\n   <g id=\"text_1\">\r\n    <!-- Label: 3 -->\r\n    <g transform=\"translate(66.966563 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\nM 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nz\r\n\" id=\"DejaVuSans-98\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path d=\"M 11.71875 12.40625 \r\nL 22.015625 12.40625 \r\nL 22.015625 0 \r\nL 11.71875 0 \r\nz\r\nM 11.71875 51.703125 \r\nL 22.015625 51.703125 \r\nL 22.015625 39.3125 \r\nL 11.71875 39.3125 \r\nz\r\n\" id=\"DejaVuSans-58\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-76\"/>\r\n     <use x=\"55.712891\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"116.992188\" xlink:href=\"#DejaVuSans-98\"/>\r\n     <use x=\"180.46875\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"241.992188\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"269.775391\" xlink:href=\"#DejaVuSans-58\"/>\r\n     <use x=\"303.466797\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"335.253906\" xlink:href=\"#DejaVuSans-51\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pe7074252af\">\r\n   <rect height=\"167.4\" width=\"167.4\" x=\"7.2\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# plot some exampels\n",
    "data_iter = iter(data_loader)\n",
    "images, labels = data_iter.next()\n",
    "N = 3\n",
    "\n",
    "if N > BATCH_SIZE:\n",
    "    N = BATCH_SIZE\n",
    "\n",
    "f, ax = plt.subplots(1, N, figsize=(3*N, 6))\n",
    "for i in range(N):\n",
    "    if N == 1:\n",
    "        ax.imshow(images[i, 0], cmap='gray')\n",
    "        ax.set_title(f'Label: {labels[i]}')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax[i].imshow(images[i, 0], cmap='gray')\n",
    "        ax[i].set_title(f'Label: {labels[i]}')\n",
    "        ax[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Instantiate Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Model Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape\n",
    "x_shape = images.shape[2:4]\n",
    "x_dim = x_shape[0] * x_shape[1]\n",
    "\n",
    "h_dim = 256\n",
    "z_dim = 16\n",
    "T = 10"
   ]
  },
  {
   "source": [
    "### Create Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = DRAW(\n",
    "    x_dim=x_dim,\n",
    "    h_dim=h_dim, \n",
    "    z_dim=z_dim, \n",
    "    T=T, \n",
    "    x_shape=x_shape\n",
    ").to(device)\n",
    "\n",
    "# define optimizer and scheduler for the leraning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, 0.5)\n",
    "\n",
    "# Use binary cross-entropy loss\n",
    "loss = nn.BCELoss(reduction='none').to(device)"
   ]
  },
  {
   "source": [
    "# Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Hyper Parameters etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "source": [
    "### Training Loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 227/60000 [02:06<9:16:31,  1.79it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-68567fef3371>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mx_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkld\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mx_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sap98\\Documents\\GitHub\\ml-library\\notebooks\\..\\models\\draw.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;31m# use attention to read image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mr_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_dec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;31m# pass throuygh encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sap98\\Documents\\GitHub\\ml-library\\notebooks\\..\\models\\draw.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, x, x_hat, h)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# compute filterbank matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         F_X, F_Y = compute_filterbanks(\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfix_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mfix_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sap98\\Documents\\GitHub\\ml-library\\notebooks\\..\\models\\draw.py\u001b[0m in \u001b[0;36mcompute_filterbanks\u001b[1;34m(A, B, log_var, gt_X, gt_Y, log_dt, N)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_filterbanks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# retrieve non-log versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_var\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# calculate grid center\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for x, _ in tqdm(data_loader):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = x.view(batch_size, -1).to(device)\n",
    "        x_hat, kld = model(x)\n",
    "        x_hat = torch.sigmoid(x_hat)\n",
    "\n",
    "        reconstruction = loss(x_hat, x).sum(1)\n",
    "        kl = kld.sum(1)\n",
    "        elbo = torch.mean(reconstruction + kl)\n",
    "\n",
    "        elbo.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    # 1 forward pass in test set for loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # if epoch % 1 == 0:\n",
    "          \n",
    "        \n",
    "        # print train loss and save sample + recon\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"\\nLoss at step {}: {}\".format(epoch, elbo.item()))\n",
    "            x_sample = model.sample()\n",
    "            save_image(x_hat, \"reconstruction-{}.jpg\".format(epoch))\n",
    "            save_image(x_sample, \"sample-{}.jpg\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}