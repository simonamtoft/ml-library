{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own imports/\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    torch.cuda.empty_cache()\n",
    "else: \n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "source": [
    "# Define Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom to top model dimensions\n",
    "x_dim = 784\n",
    "z_dim = [32, 16, 8]\n",
    "h_dim = [256, 128, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LadderVAE\n",
    "model = LadderVAE([x_dim, z_dim, h_dim])\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "source": [
    "# Training the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper parameters\n",
    "learning_rate = 3e-4\n",
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "from data import get_mnist\n",
    "train, test = get_mnist(location=\"./\", batch_size=64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and linear warm-up constant\n",
    "from utils import DeterministicWarmup, bce_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "gamma = DeterministicWarmup(n=50, t_max=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (u, _) in train:\n",
    "        u = Variable(u).to(device)\n",
    "\n",
    "        reconstruction = model(u)\n",
    "        \n",
    "        likelihood = -bce_loss(reconstruction, u)\n",
    "        elbo = likelihood - next(gamma) * model.kld\n",
    "        \n",
    "        L = -torch.mean(elbo)\n",
    "\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += L.data.item()\n",
    "\n",
    "    m = len(train)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch+1}\\tL: {total_loss/m:.2f}\")"
   ]
  },
  {
   "source": [
    "# Sampling from Generative model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "model.eval()\n",
    "x_mu = model.sample(Variable(torch.randn(16, 8)).to(device))\n",
    "\n",
    "# Plot\n",
    "f, axarr = plt.subplots(2, 8, figsize=(18, 6))\n",
    "samples = x_mu.data.view(-1, 28, 28).cpu().numpy()\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(samples[i])\n",
    "    ax.axis(\"off\")"
   ]
  }
 ]
}